# Clean and analyze social media usage data with Python
# Coursera Project Network

# Task 1
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random

# Task 2
# Define the list of categories
categories = ['Food', 'Travel', 'Fashion', 'Fitness', 'Music', 'Culture', 'Family', 'Health']

# Create the DataFrame
df_tweets = pd.DataFrame(columns=['Date', 'Category', 'Likes'])

# Populate the 'Date' column
date_range = pd.date_range(start='2023-01-01', end='2023-12-31')
df_tweets['Date'] = [random.choice(date_range) for _ in range(1000)]

# Populate the 'Category' column
df_tweets['Category'] = random.choices(categories, weights=None, k=1000)

# Populate the 'Likes' column
df_tweets['Likes'] = np.random.randint(0, 1001, size=1000)

# Set the number of periods (n)
n = 500

# Create the data dictionary
data = {
    'Date': pd.date_range('2021-01-01', periods=n),
    'Category': [random.choice(categories) for _ in range(n)],
    'Likes': np.random.randint(0, 10000, size=n)
}

# Create a DataFrame 
df = pd.DataFrame(data)

# Task 3
# Create a DataFrame from the data dictionary
df = pd.DataFrame(data)

# Display the first 5 rows
styled_df = df.head().style.set_properties(**{'text-align': 'left'})
display(styled_df) # Removed .render()

# Print the DataFrame information
print("\nDataFrame Information:\n")
print(df.info())

# Print the DataFrame description (summary statistics)
print("\nDataFrame Description:\n")
print(df.describe().to_markdown(numalign="left", stralign="left"))

# Print the count of each 'Category' element
print("\nCount of each Category:\n")
print(df['Category'].value_counts().to_markdown(numalign="left", stralign="left"))

# Task 4

# Drop rows with null values (if any)
df.dropna(inplace=True)

# Drop duplicate rows (if any)
df.drop_duplicates(inplace=True)

# Convert the 'Date' column to datetime format
df['Date'] = pd.to_datetime(df['Date'])

# Convert the 'Likes' column to integer
df['Likes'] = df['Likes'].astype(int)

# Display the updated DataFrame information to verify the changes
print("\nUpdated DataFrame Information after cleaning:\n")
print(df.info())

# Visualize the data using Seaborn
# Histogram of Likes
sns.histplot(data=df, x='Likes')
plt.title('Distribution of Likes')
plt.show()

# Boxplot of Likes by Category
sns.boxplot(data=df, x='Category', y='Likes')
plt.title('Likes by Category')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.show()

# Perform statistics on the data
# Print the mean of the 'Likes' category
mean_likes = df['Likes'].mean()
print(f"\nMean of Likes: {mean_likes}")

# Print the mean of each Category's 'Likes'
mean_likes_by_category = df.groupby('Category')['Likes'].mean()
print("\nMean Likes by Category:\n")
print(mean_likes_by_category.to_markdown(numalign="left", stralign="left"))

# Print the correlation matrix
correlation_matrix = df[['Likes']].corr() # Only include numerical columns in correlation calculation
print("\nCorrelation Matrix:\n")
print(correlation_matrix.to_markdown(numalign="left", stralign="left"))

# Task 6 - Conclusions

from IPython.display import Markdown, display

print("\n*Conclusions:*\n")

# Discuss the process and key findings
conclusion = """
This project involved generating random social media data, exploring it using Pandas, and visualizing key insights with Seaborn. 

The data cleaning process ensured data integrity by handling nulls, duplicates, and data type conversions. Visualizations like the histogram and boxplot revealed the distribution of 'Likes' and how they vary across different 'Categories.' Calculating the mean 'Likes' overall and per category provided further quantitative insights.

**Key Findings:**

* The 'Likes' distribution is somewhat skewed right, indicating a higher frequency of posts with *lower* likes. 
* The boxplot highlights variations in 'Likes' across categories, suggesting potential differences in engagement levels. 
* 'Music' appears to have the highest average number of likes, while 'Food' has the lowest.

This project demonstrates proficiency in data generation, cleaning, exploration, visualization, and basic statistical analysis using Python, Pandas, and Seaborn. 

**Potential Improvements:**

* Incorporate more realistic data generation techniques, considering factors like time of day, user demographics, and content sentiment.
* Explore advanced visualizations to uncover deeper patterns and relationships within the data.
* Apply statistical tests to assess the significance of observed differences between categories.
* Develop an interactive dashboard to enable dynamic exploration of the data and insights.

Overall, this project showcases a solid foundation in data analysis and a willingness to learn and improve.
"""

# Use IPython.display.Markdown to render the conclusion with proper formatting
display(Markdown(conclusion))